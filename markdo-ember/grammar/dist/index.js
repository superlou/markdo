import { ContextTracker, ExternalTokenizer, LRParser } from '@lezer/lr';

// This file was generated by lezer-generator. You probably shouldn't edit it.
const indent = 14,
  dedent = 15,
  blankLineStart = 16;

class IndentLevel {
  constructor(parent, depth) {
    this.parent = parent;
    this.depth = depth;
    this.hash = (parent ? parent.hash + parent.hash << 8 : 0) + depth + (depth << 4);
  }
}

const trackIndent = new ContextTracker({
  start: new IndentLevel(null, 0),
  shift(context, term, stack, input) {
    if (term == indent) return new IndentLevel(context, stack.pos - input.pos)
    if (term == dedent) return context.parent
    return context
  },
  hash: context => context.hash
});

const newline = 10, space = 32, tab = 9, hash = 35;

const indentation = new ExternalTokenizer((input, stack) => {
  let prev = input.peek(-1);
  if (prev != -1 && prev != newline) return
  let spaces = 0;
  while (input.next == space || input.next == tab) { input.advance(); spaces++; }
  if ((input.next == newline || input.next == hash) && stack.canShift(blankLineStart)) {
    input.acceptToken(blankLineStart, -spaces);
  } else if (spaces > stack.context.depth) {
    input.acceptToken(indent);
  } else if (spaces < stack.context.depth) {
    input.acceptToken(dedent, -spaces);
  }
});

// This file was generated by lezer-generator. You probably shouldn't edit it.
const parser = LRParser.deserialize({
  version: 14,
  states: "$[Q]QROOPeOPOOOjQRO'#C_OrQTO'#CcOOQP'#Cr'#CrOOQP'#Cg'#CgQ]QROOPwOQO)C>cOOQP'#Co'#CoO!VQRO,58yOjQRO,58}OOQP-E6e-E6ePOOO'#Cf'#CfPwOQO/'3}POOO/'3}/'3}O]QRO'#CbOOQP1G.g1G.gO!kQRO1G.iPOOO-E6d-E6dPOOO49)i49)iO#PQRO,58|OOQP'#Ch'#ChO#_QRO7+$TOOQP1G.h1G.hOOQP-E6f-E6f",
  stateData: "#s~ObOSPOS`PQ~OSQOWRO~O`VO~OdWOeWO~OXYO~OP[Ob[OdWOeWO~O^_OSRaWRa]Ra_RaeRa~O^_OSViWVi]Vi_VieVi~OSQOWRO_gOegO~O^_OSVqWVq]Vq_VqeVq~O",
  goto: "!ogPPPhPhnhPPu{!VPPPPPP!]PP!iXSOU_dQ`XTeafQ]VRb]QUOSZUdRd_QfaRhfQXQQ^VQaYRc]XTOU_d",
  nodeNames: "âš  Comment Tree Atom Identifier Section Block Task TaskBox Description",
  maxTerm: 22,
  context: trackIndent,
  skippedNodes: [0,1,10],
  repeatNodeCount: 3,
  tokenData: "#t~RYXYqYZ|pqqst!R!Q![!y!c!}!y!}#O#^#R#S!y#T#o!y~~#o~vQb~XYqpqq~!ROd~~!USOY!bZ;'S!b;'S;=`!s<%lO!b~!gSP~OY!bZ;'S!b;'S;=`!s<%lO!b~!vP;=`<%l!bR#QSXQSP!Q![!y!c!}!y#R#S!y#T#o!y~#aPpq#d~#gP#P#Q#j~#oOW~~#tOe~",
  tokenizers: [indentation, 0, 1],
  topRules: {"Tree":[0,2]},
  tokenPrec: 0
});

export { parser };
